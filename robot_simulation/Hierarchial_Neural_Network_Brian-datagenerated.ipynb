{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Hierarchial_Neural_Network Brian.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "distance_definitions = {'near':.95,'medium':.7} # averaged output by perceptron\n",
        "wheel_definitions = {'slow':.5,'medium':.8}\n",
        "near_sensor = lambda x: 0 if (x >= distance_definitions['near']) else ( 1 if x >= distance_definitions['medium'] else 2)\n",
        "measure_wheel = lambda x: 0 if (x < wheel_definitions['slow']) else ( 1 if x < wheel_definitions['medium'] else 0)\n",
        "turn_away = lambda x: 0 if (near_sensor(x)==0) else 2\n",
        "actions = {'left':0,'right':1,'forward':2}\n",
        "\n",
        "#near, medium, far - 0,1,2\n",
        "# To implement next - when torque is greater, make sensor data change\n",
        "generated_points = 1000\n",
        "\n",
        "def generate_sensor_data(evaluation):\n",
        "    # randomly generate voltage value\n",
        "    # perceptron tends to over-estimate how close something is to compensate\n",
        "    # for any signal loss due to noise/angle\n",
        "    # skew probability to produce smaller numbers more often, to balance out this trend\n",
        "    sensor_data_front = [random.triangular(0,2.9,0) for x in range(generated_points)]\n",
        "    sensor_data_front_target = [evaluation(x) for x in sensor_data_front]\n",
        "    sensor_data_front = pd.DataFrame(zip(sensor_data_front,sensor_data_front_target))\n",
        "    sensor_data_front.columns = ['x','y']\n",
        "    return(sensor_data_front)\n",
        "\n",
        "\n",
        "def generate_decisions(evaluation,turnaway):\n",
        "    sensor_data_front = [random.triangular(0,2.9,0) for x in range(generated_points)]\n",
        "    sensor_data_front_target = [evaluation(x) for x in sensor_data_front]\n",
        "    sensor_data_decision = [turnaway(x) for x in sensor_data_front]\n",
        "    sensor_data_front = pd.DataFrame(zip(sensor_data_front,sensor_data_decision,sensor_data_front_target))\n",
        "    sensor_data_front.columns = ['x','decision','y']\n",
        "    return(sensor_data_front)\n",
        "\n",
        "sensor_front_data = generate_sensor_data(evaluation=near_sensor)\n",
        "sensor_front_data_decision = generate_decisions(evaluation=near_sensor,turnaway=turn_away)\n",
        "\n",
        "sensor_front_data_decision\n",
        "# wheel_lf_data = generate_sensor_data(evaluation=measure_wheel)\n",
        "# wheel_rf_data = generate_sensor_data(evaluation=measure_wheel)\n",
        "# wheel_lb_data = generate_sensor_data(evaluation=measure_wheel)\n",
        "# wheel_rb_data = generate_sensor_data(evaluation=measure_wheel)\n",
        "# from keras.utils.np_utils import to_categorical\n",
        "\n",
        "class NeuralNet():\n",
        "    def __init__(self,x,y,output,name):\n",
        "        self.X = x\n",
        "        self.y = y\n",
        "        self.output=output\n",
        "        self.name=name\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "        # model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "        # model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "\n",
        "        model.add(keras.layers.Dense(output,activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            loss=keras.losses.SparseCategoricalCrossentropy(),#'sparse_categorical_cross_entropy',\n",
        "            optimizer=keras.optimizers.SGD(),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        self.model=model\n",
        "\n",
        "    def train(self,**args):\n",
        "        pass\n",
        "\n",
        "    def load_model(self,model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self,test,**args):\n",
        "        predictions=self.model.predict(test)\n",
        "        return(predictions)\n",
        "\n",
        "    def cat_predict(self,test,**args):\n",
        "        predictions=self.model.predict_classes(test)\n",
        "        return(predictions)\n",
        "\n",
        "    def save(self,path):\n",
        "        self.model.save(path,overwrite=True)\n",
        "\n",
        "class InfraredNet(NeuralNet):\n",
        "    def __init__(self,input,target,output,name):\n",
        "        super().__init__(input,target,output,name)\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "        # model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "        # model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "\n",
        "        model.add(keras.layers.Dense(output,activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            loss=keras.losses.SparseCategoricalCrossentropy(),#'sparse_categorical_cross_entropy',\n",
        "            optimizer=keras.optimizers.SGD(),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        # input_sensor = keras.layers.Input(shape=input.shape[1], name=name)\n",
        "        # hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_sensor)\n",
        "        # output = keras.layers.Dense(len(set(self.y)), name=\"output\")(hidden1)\n",
        "\n",
        "        # self.model = keras.models.Model(inputs=[input_sensor], outputs=[output])\n",
        "        # self.model.compile(loss=\"sparse_categorical_entropy\",\n",
        "        #               optimizer=keras.optimizers.RMSprop(),\n",
        "        #               metrics=['accuracy'])\n",
        "        self.model=model\n",
        "\n",
        "    def train(self):\n",
        "        self.model.fit(self.X,self.y,epochs=30,batch_size=32)\n",
        "\n",
        "    def mini_train(self,epochs):\n",
        "        self.model.fit(self.X,self.y,epochs=epochs)\n",
        "    # def predict(self,test):\n",
        "    #   self.model.predict(test)\n",
        "\n",
        "\n",
        "class MainNet(NeuralNet):\n",
        "    def __init__(self,input,target,output,name):\n",
        "        super().__init__(input,target,output,name)\n",
        "        model = keras.models.Sequential()\n",
        "        model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "        # model.add(keras.layers.Dense(20,activation='relu')) # A layer connected to all layers\n",
        "\n",
        "        model.add(keras.layers.Dense(output,activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            loss=keras.losses.SparseCategoricalCrossentropy(),#'sparse_categorical_cross_entropy',\n",
        "            optimizer=keras.optimizers.SGD(),\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        self.model=model\n",
        "\n",
        "    def train(self,epochs=30):\n",
        "        #print(self.X.shape,self.y.shape)\n",
        "        print(\"x: \",self.X)\n",
        "        print(\"y: \",self.y)\n",
        "        self.model.fit(self.X,self.y,epochs=epochs,batch_size=32,shuffle=True)\n",
        "\n",
        "    # def predict(self,test):\n",
        "    #   self.model.predict(self,test)\n",
        "\n",
        "class TreeNet():\n",
        "    def __init__(self,sensors,mainnet=None):\n",
        "        # assert(type(models[0]) == NeuralNet)\n",
        "        self.sensors = sensors\n",
        "\n",
        "        self.mainnet = mainnet\n",
        "\n",
        "\n",
        "    # Train all models\n",
        "    def train(self,data,y,train_sensors=True,epochs=50):\n",
        "        all_predictions = []\n",
        "\n",
        "        for model,sensor_data in zip(self.sensors,data):\n",
        "            if(train_sensors==True):\n",
        "                print(\"Training \" + model.name)\n",
        "                model.X=sensor_data[0]\n",
        "                model.y=sensor_data[1]\n",
        "                model.train()\n",
        "            predictions = model.predict(sensor_data[0])\n",
        "            all_predictions.append(predictions)\n",
        "        # all_predictions\n",
        "        training_data=np.concatenate((all_predictions),axis=1)\n",
        "        print(training_data.shape)\n",
        "        self.mainnet.X = training_data\n",
        "        self.mainnet.y = y\n",
        "        print(\"Training mainnet...\")\n",
        "        if epochs == 50:\n",
        "            self.mainnet.train()\n",
        "        else:\n",
        "            self.mainnet.mini_train(epochs=epochs)\n",
        "        # return(training_data)#training_data)\n",
        "\n",
        "\n",
        "    def standardize_data(self,X):\n",
        "        return([[x] for x in X])\n",
        "\n",
        "\n",
        "    def standardize_data_all(self,X):\n",
        "        all_data=[]\n",
        "        for x in X:\n",
        "            res=[]\n",
        "            for sub_x in x:\n",
        "                res.append([sub_x])\n",
        "            all_data.append(res)\n",
        "        return(all_data)\n",
        "\n",
        "    # Use predictions of models to train main net\n",
        "    def predict(self,X):\n",
        "        all_predictions = []\n",
        "\n",
        "        for model,sensor_data in zip(self.sensors,X):\n",
        "            predictions = model.predict(sensor_data)\n",
        "            all_predictions.append(predictions)\n",
        "\n",
        "        # all_predictions\n",
        "        test_data=np.concatenate((all_predictions),axis=1)\n",
        "        # print(training_data)\n",
        "        predictions=self.mainnet.predict(test_data)\n",
        "        return(predictions)\n",
        "\n",
        "    def predict_class(self,X):\n",
        "        all_predictions = []\n",
        "\n",
        "        for model,sensor_data in zip(self.sensors,X):\n",
        "\n",
        "            predictions = model.predict(sensor_data)\n",
        "            all_predictions.append(predictions)\n",
        "        # all_predictions\n",
        "        test_data=np.concatenate((all_predictions),axis=1)\n",
        "        # print(test_data)\n",
        "        # print(training_data)\n",
        "        predictions=self.mainnet.cat_predict(test_data)\n",
        "        return(predictions)\n",
        "\n",
        "\n",
        "# defining training set for infrared nets --------------------------------------------------------------------\n",
        "train_x = sensor_front_data_decision[['x']].values\n",
        "train_y = sensor_front_data_decision[['y']].values\n",
        "# train = []\n",
        "# for i in range(7):\n",
        "#     train.append((train_x, train_y))\n",
        "\n",
        "\n",
        "# defining each sensor ---------------------------------------------------------------------------------------\n",
        "infr_net = InfraredNet(input=train_x,target = train_y,output=3,name='infrared')\n",
        "infr_net.train()\n",
        "\n",
        "infrared_net_list = [infr_net,infr_net,infr_net,infr_net,infr_net,infr_net,infr_net]\n",
        "main_net = MainNet(input=None,target=None,output=3,name=\"main_net\")\n",
        "\n",
        "\n",
        "# for net in infrared_net_list:\n",
        "#     net.train()\n",
        "# -------------------------------------------------------------------------------------------------------------\n",
        "# set up tree net, train tree net with manually collected data\n",
        "tree_net = TreeNet(infrared_net_list,mainnet=main_net)\n",
        "\n",
        "# data reformatting -------------------------------------------------------------------------------------------\n",
        "# problem: \"[0,0,0,0,0,0,0]\" keeps being interpreted as string instead of array\n",
        "# either try to convert to right type or change store type\n",
        "from ast import literal_eval\n",
        "from data_process import get_float_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"dataset.csv\")\n",
        "df['action'] = [int(i) for i in df['action']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['s0','s1','s2','s3','s4','s5','s6']], df[['action']], test_size=0.30, random_state=42)\n",
        "truth = y_train.values\n",
        "truth_test = y_test.values\n",
        "\n",
        "x0 = X_train[['s0']].values\n",
        "x1 = X_train[['s1']].values\n",
        "x2 = X_train[['s2']].values\n",
        "x3 = X_train[['s3']].values\n",
        "x4 = X_train[['s4']].values\n",
        "x5 = X_train[['s5']].values\n",
        "x6 = X_train[['s6']].values\n",
        "\n",
        "y0 = [near_sensor(i) for i in x0]\n",
        "y1 = [near_sensor(i) for i in x1]\n",
        "y2 = [near_sensor(i) for i in x2]\n",
        "y3 = [near_sensor(i) for i in x3]\n",
        "y4 = [near_sensor(i) for i in x4]\n",
        "y5 = [near_sensor(i) for i in x5]\n",
        "y6 = [near_sensor(i) for i in x6]\n",
        "\n",
        "\n",
        "train = [(x0,y0), (x1,y1), (x2,y2), (x3,y3), (x4,y4), (x5,y5), (x6,y6)]\n",
        "tree_net.train(data=train, y=truth, train_sensors=False)\n",
        "\n",
        "x0 = X_test[['s0']].values\n",
        "x1 = X_test[['s1']].values\n",
        "x2 = X_test[['s2']].values\n",
        "x3 = X_test[['s3']].values\n",
        "x4 = X_test[['s4']].values\n",
        "x5 = X_test[['s5']].values\n",
        "x6 = X_test[['s6']].values\n",
        "\n",
        "y0 = [near_sensor(i) for i in x0]\n",
        "y1 = [near_sensor(i) for i in x1]\n",
        "y2 = [near_sensor(i) for i in x2]\n",
        "y3 = [near_sensor(i) for i in x3]\n",
        "y4 = [near_sensor(i) for i in x4]\n",
        "y5 = [near_sensor(i) for i in x5]\n",
        "y6 = [near_sensor(i) for i in x6]\n",
        "test = [x0,x1,x2,x3,x4,x5,x6]\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "32/32 [==============================] - 1s 1ms/step - loss: 1.1108 - accuracy: 0.4310\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9995 - accuracy: 0.8530\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.8420\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.8520\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.8273 - accuracy: 0.8420\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.8500\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.8530\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.8600\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.8600\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.8680\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8650\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8670\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8740\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8720\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8760\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8730\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8620\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8750\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8690\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8730\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8690\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8700\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8800\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8650\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8690\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.8750\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8660\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2841 - accuracy: 0.8710\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.8730\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8660\n",
            "(1468, 21)\n",
            "Training mainnet...\n",
            "x:  [[9.6889919e-01 2.3421163e-02 7.6796045e-03 ... 3.7024252e-04\n",
            "  1.5705751e-02 9.8392397e-01]\n",
            " [9.9644780e-01 3.0627560e-03 4.8939226e-04 ... 3.7024252e-04\n",
            "  1.5705751e-02 9.8392397e-01]\n",
            " [9.6546483e-01 2.5789259e-02 8.7460121e-03 ... 9.9483973e-01\n",
            "  4.3670083e-03 7.9323776e-04]\n",
            " ...\n",
            " [9.9447638e-01 4.6576397e-03 8.6597970e-04 ... 8.8870114e-01\n",
            "  7.4680425e-02 3.6618497e-02]\n",
            " [1.7759772e-03 3.4847151e-02 9.6337688e-01 ... 9.9755019e-01\n",
            "  2.1480024e-03 3.0182581e-04]\n",
            " [8.8761869e-04 2.4120489e-02 9.7499192e-01 ... 3.7024252e-04\n",
            "  1.5705749e-02 9.8392397e-01]]\n",
            "y:  [[1]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [2]\n",
            " [0]]\n",
            "Epoch 1/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 1.0773 - accuracy: 0.3951\n",
            "Epoch 2/30\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1.0155 - accuracy: 0.4734\n",
            "Epoch 3/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.9678 - accuracy: 0.4918\n",
            "Epoch 4/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.9242 - accuracy: 0.5245\n",
            "Epoch 5/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.8825 - accuracy: 0.5593\n",
            "Epoch 6/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.8423 - accuracy: 0.6144\n",
            "Epoch 7/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.8066 - accuracy: 0.6478\n",
            "Epoch 8/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.6723\n",
            "Epoch 9/30\n",
            "46/46 [==============================] - 0s 929us/step - loss: 0.7519 - accuracy: 0.6819\n",
            "Epoch 10/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.7334 - accuracy: 0.6982\n",
            "Epoch 11/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.7050\n",
            "Epoch 12/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.7119\n",
            "Epoch 13/30\n",
            "46/46 [==============================] - 0s 861us/step - loss: 0.6903 - accuracy: 0.7193\n",
            "Epoch 14/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.7234\n",
            "Epoch 15/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6713 - accuracy: 0.7330\n",
            "Epoch 16/30\n",
            "46/46 [==============================] - 0s 947us/step - loss: 0.6629 - accuracy: 0.7405\n",
            "Epoch 17/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.7398\n",
            "Epoch 18/30\n",
            "46/46 [==============================] - 0s 867us/step - loss: 0.6483 - accuracy: 0.7418\n",
            "Epoch 19/30\n",
            "46/46 [==============================] - 0s 992us/step - loss: 0.6415 - accuracy: 0.7500\n",
            "Epoch 20/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.7480\n",
            "Epoch 21/30\n",
            "46/46 [==============================] - 0s 928us/step - loss: 0.6307 - accuracy: 0.7432\n",
            "Epoch 22/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.7493\n",
            "Epoch 23/30\n",
            "46/46 [==============================] - 0s 996us/step - loss: 0.6209 - accuracy: 0.7534\n",
            "Epoch 24/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.7466\n",
            "Epoch 25/30\n",
            "46/46 [==============================] - 0s 927us/step - loss: 0.6130 - accuracy: 0.7439\n",
            "Epoch 26/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6095 - accuracy: 0.7486\n",
            "Epoch 27/30\n",
            "46/46 [==============================] - 0s 879us/step - loss: 0.6062 - accuracy: 0.7609\n",
            "Epoch 28/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.7534\n",
            "Epoch 29/30\n",
            "46/46 [==============================] - 0s 974us/step - loss: 0.6015 - accuracy: 0.7568\n",
            "Epoch 30/30\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.7582\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "predictions=tree_net.predict_class(test)\n",
        "# accuracy_score(truth_test,predictions)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "accuracy_score(truth_test,predictions)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7619047619047619"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}